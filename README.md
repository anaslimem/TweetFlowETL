# TweetFlowETL ğŸ¦ğŸ’¾

An ETL (Extract, Transform, Load) pipeline project that extracts tweets from the Twitter API, transforms the data, and loads it into Azure Blob Storage.


## ğŸ“Œ Project Overview

This project demonstrates an end-to-end data pipeline using **Apache Airflow** to automate the following:

- **Extract** tweet data using Twitter API (e.g., tweets by Elon Musk).
- **Transform** the data (filtering, restructuring, cleaning).
- **Load** the final JSON data into **Azure Blob Storage** (Container: `tweet`).


## ğŸ“ Folder Structure

â”œâ”€â”€ dags/

â”‚ â””â”€â”€ twitter_ETL_dag.py # Airflow DAG definition

â”œâ”€â”€ logs/ # Airflow logs

â”œâ”€â”€ plugins/ # Custom Airflow plugins (if any)

â”œâ”€â”€ .env # Environment variables

â”œâ”€â”€ docker-compose.yaml # Docker environment setup 
for Airflow

â”œâ”€â”€ elonmusk_tweets.json # Extracted/Transformed data (sample)

â”œâ”€â”€ README.md # Project documentation

â”œâ”€â”€ requirements.txt # Python dependencies


### Prerequisites

- Docker
- Twitter Developer Account (Bearer Token)
- Azure Blob Storage Account

### Clone the Repo

```bash
git clone https://github.com/anaslimem/TweetFlowETL.git
cd TweetFlowETL
```

## Set Environment Variables
### Create a .env file and add:

```bash
TWITTER_BEARER_TOKEN=your_token_here
AZURE_STORAGE_CONNECTION_STRING=your_connection_string
```

## Build & Start Airflow

```bash
docker-compose up --build
```

## ğŸ’¾ Output
The transformed tweets are saved as a JSON file and uploaded to Azure Blob Storage in a container named tweet.

## ğŸ§° Tools & Technologies

- Python

- Apache Airflow

- Twitter API v2

- Azure Blob Storage

- Docker

## ğŸ“¬ Contact
Made with â¤ï¸ by Anas Limem
Linkedin: 
https://www.linkedin.com/in/anaslimem/



